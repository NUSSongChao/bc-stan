eta <- D.COMP[,1] # simulation output
xc <- D.COMP[,2:(1+p)] # simulation input
tc <- D.COMP[,(2+p):(1+p+q)] # calibration parameters
eta_mu <- mean(eta, na.rm = TRUE) # mean value
eta_sd <- sd(eta, na.rm = TRUE) # standard deviation
y <- (y - eta_mu) / eta_sd
eta <- (eta - eta_mu) / eta_sd
x_pred <- xf
n_pred <- ifelse(p==1,length(xf),nrow(xf))
x <- rbind(xf,xc,x_pred)
if (p==1){
x_min <- min(x, na.rm = TRUE)
x_max <- max(x, na.rm = TRUE)
xf <- (xf - x_min) / (x_max - x_min)
xc <- (xc - x_min) / (x_max - x_min)
x_pred <- (x_pred - x_min) / (x_max - x_min)
}else{
for (i in (1:ncol(x))) {
x_min <- min(x[,i], na.rm = TRUE)
x_max <- max(x[,i], na.rm = TRUE)
xf[,i] <- (xf[,i] - x_min) / (x_max - x_min)
xc[,i] <- (xc[,i] - x_min) / (x_max - x_min)
x_pred[,i] <- (x_pred[,i] - x_min) / (x_max - x_min)
}
}
for (j in (1:ncol(tc))) {
tc_min <- min(tc[,j], na.rm = TRUE)
tc_max <- max(tc[,j], na.rm = TRUE)
tc[,j] <- (tc[,j] - tc_min) / (tc_max - tc_min)
}
stanDat <- list(n=n,m=m,n_pred=n_pred,p=p,q=q,
xf=as.matrix(xf),xc=as.matrix(xc),x_pred=as.matrix(x_pred),
tc=tc,y=y,eta=eta)
ptm <- proc.time()
fit <- stan(file = paste(predictor,'_pred_',prior,'.stan',sep=''),
data = stanDat,
iter = 500,
chains = n_chains,
cores = getOption("mc.cores", n_chains))
setwd("~/Dropbox/Toshiba Projects/Compare Optimization Bayesian Calibration/Models/BCTutorial/with_predictive_inference")
setwd("~/Dropbox/Toshiba Projects/Compare Optimization Bayesian Calibration/Models/BCTutorial/with_predictive_inference")
rm(list = ls())
library(rstan)
library(fields)
library(MASS)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
nVar <- 4; nSim <- 30
year <- 2013; xn <- 3
# possible priors:'flat', 'normal_stdev0_2', 'normal_stdev0_05'
prior <- 'flat'
# possible predictors:'y', 'eta'
predictor <- 'y'
n_chains <- 4
mainDir <- paste(nVar,'CalibrationParams/',sep='')
D.COMP <- read.csv(paste(mainDir,'AY',year,'_xn',xn,
'_DATACOMP.csv',sep=''),header=TRUE)
D.FIELD <- read.csv(paste(mainDir,'AY',year,'_xn',xn,
'_DATAFIELD.csv',sep=''),header=TRUE)
# get dimension of dataset
# D.FIELD: field dataset (Table B.1)
# D.COMP: computer simulation dataset (Table B.2)
p <- ncol(D.FIELD) - 1 # number of input factors
q <- ncol(D.COMP) - p - 1 # number of calibration parameters
n <- nrow(D.FIELD) # sample size of observed field data
m <- nrow(D.COMP) # sample size of computer simulation data
# change columne names
colnames(D.FIELD) <- c("y",paste("x", seq(1:p),sep=''))
colnames(D.COMP) <- c("eta",paste("x", seq(1:p),sep=''),
paste("tc", seq(1:q),sep=''))
# extract data from field dataset and computer simulation dataset
# assuming D.FIELD and D.COMP is in same format as Tables B.1 and B.2
y <- D.FIELD[,1] # observed output
xf <- D.FIELD[,2:(1+p)] # observed input
eta <- D.COMP[,1] # simulation output
xc <- D.COMP[,2:(1+p)] # simulation input
tc <- D.COMP[,(2+p):(1+p+q)] # calibration parameters
eta_mu <- mean(eta, na.rm = TRUE) # mean value
eta_sd <- sd(eta, na.rm = TRUE) # standard deviation
y <- (y - eta_mu) / eta_sd
eta <- (eta - eta_mu) / eta_sd
x_pred <- xf
n_pred <- ifelse(p==1,length(xf),nrow(xf))
# Put design points xf and xc on [0,1]
x <- rbind(xf,xc,x_pred)
if (p==1){
x_min <- min(x, na.rm = TRUE)
x_max <- max(x, na.rm = TRUE)
xf <- (xf - x_min) / (x_max - x_min)
xc <- (xc - x_min) / (x_max - x_min)
x_pred <- (x_pred - x_min) / (x_max - x_min)
}else{
for (i in (1:ncol(x))) {
x_min <- min(x[,i], na.rm = TRUE)
x_max <- max(x[,i], na.rm = TRUE)
xf[,i] <- (xf[,i] - x_min) / (x_max - x_min)
xc[,i] <- (xc[,i] - x_min) / (x_max - x_min)
x_pred[,i] <- (x_pred[,i] - x_min) / (x_max - x_min)
}
}
# Put calibration parameters t on domain [0,1]
for (j in (1:ncol(tc))) {
tc_min <- min(tc[,j], na.rm = TRUE)
tc_max <- max(tc[,j], na.rm = TRUE)
tc[,j] <- (tc[,j] - tc_min) / (tc_max - tc_min)
}
stanDat <- list(n=n,m=m,n_pred=n_pred,p=p,q=q,
xf=as.matrix(xf),xc=as.matrix(xc),x_pred=as.matrix(x_pred),
tc=tc,y=y,eta=eta)
ptm <- proc.time()
fit <- stan(file = paste(predictor,'_pred_',prior,'.stan',sep=''),
data = stanDat,
iter = 500,
chains = n_chains,
cores = getOption("mc.cores", n_chains))
setwd("~/Dropbox/Toshiba Projects/Compare Optimization Bayesian Calibration/Models/BCTutorial/with_predictive_inference")
rm(list = ls())
library(rstan)
library(fields)
library(MASS)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
nVar <- 4; nSim <- 30
year <- 2013; xn <- 3
# possible priors:'flat', 'normal_stdev0_2', 'normal_stdev0_05'
prior <- 'normal_stdev0_2'
# possible predictors:'y', 'eta'
predictor <- 'y'
n_chains <- 4
mainDir <- paste(nVar,'CalibrationParams/',sep='')
D.COMP <- read.csv(paste(mainDir,'AY',year,'_xn',xn,
'_DATACOMP.csv',sep=''),header=TRUE)
D.FIELD <- read.csv(paste(mainDir,'AY',year,'_xn',xn,
'_DATAFIELD.csv',sep=''),header=TRUE)
p <- ncol(D.FIELD) - 1 # number of input factors
q <- ncol(D.COMP) - p - 1 # number of calibration parameters
n <- nrow(D.FIELD) # sample size of observed field data
m <- nrow(D.COMP) # sample size of computer simulation data
colnames(D.FIELD) <- c("y",paste("x", seq(1:p),sep=''))
colnames(D.COMP) <- c("eta",paste("x", seq(1:p),sep=''),
paste("tc", seq(1:q),sep=''))
y <- D.FIELD[,1] # observed output
xf <- D.FIELD[,2:(1+p)] # observed input
eta <- D.COMP[,1] # simulation output
xc <- D.COMP[,2:(1+p)] # simulation input
tc <- D.COMP[,(2+p):(1+p+q)] # calibration parameters
eta_mu <- mean(eta, na.rm = TRUE) # mean value
eta_sd <- sd(eta, na.rm = TRUE) # standard deviation
y <- (y - eta_mu) / eta_sd
eta <- (eta - eta_mu) / eta_sd
x_pred <- xf
n_pred <- ifelse(p==1,length(xf),nrow(xf))
x <- rbind(xf,xc,x_pred)
if (p==1){
x_min <- min(x, na.rm = TRUE)
x_max <- max(x, na.rm = TRUE)
xf <- (xf - x_min) / (x_max - x_min)
xc <- (xc - x_min) / (x_max - x_min)
x_pred <- (x_pred - x_min) / (x_max - x_min)
}else{
for (i in (1:ncol(x))) {
x_min <- min(x[,i], na.rm = TRUE)
x_max <- max(x[,i], na.rm = TRUE)
xf[,i] <- (xf[,i] - x_min) / (x_max - x_min)
xc[,i] <- (xc[,i] - x_min) / (x_max - x_min)
x_pred[,i] <- (x_pred[,i] - x_min) / (x_max - x_min)
}
}
for (j in (1:ncol(tc))) {
tc_min <- min(tc[,j], na.rm = TRUE)
tc_max <- max(tc[,j], na.rm = TRUE)
tc[,j] <- (tc[,j] - tc_min) / (tc_max - tc_min)
}
stanDat <- list(n=n,m=m,n_pred=n_pred,p=p,q=q,
xf=as.matrix(xf),xc=as.matrix(xc),x_pred=as.matrix(x_pred),
tc=tc,y=y,eta=eta)
ptm <- proc.time()
fit <- stan(file = paste(predictor,'_pred_',prior,'.stan',sep=''),
data = stanDat,
iter = 500,
chains = n_chains,
cores = getOption("mc.cores", n_chains))
setwd("~/Dropbox/Toshiba Projects/Compare Optimization Bayesian Calibration/Models/BCTutorial/with_predictive_inference")
rm(list = ls())
library(ggplot2)
library(plyr)
library(lhs)
getSamples <- function(predictor, prior, nVar, year, xn, nSim) {
directory <- paste(nVar,'CalibrationParams/',sep='')
D.COMP <- read.csv(paste(directory,'AY',year,'_xn',xn,
'_DATACOMP.csv',sep=''),header=TRUE)
D.FIELD <- read.csv(paste(directory,'AY',year,'_xn',xn,
'_DATAFIELD.csv',sep=''),header=TRUE)
folder <- paste(predictor,'_',prior,'_',xn,'xn_',
nVar,'tc_',nSim,'sim_',
'AY',year,sep='')
load(paste(directory,'results/',folder,'/',
'modelOutput_',prior,'_',xn,'xn_',
nVar,'tc_',nSim,'sim_',
'AY',year,'.rda',sep=''))
samples <- rstan::extract(fit)
p <- stanDat$p; q <- stanDat$q; n <- stanDat$n; m <- stanDat$m
tmax <- apply(D.COMP[,(2+p):(1+p+q)],2,max)
tmin <- apply(D.COMP[,(2+p):(1+p+q)],2,min)
for(ii in (1:q)){
samples$tf[,ii] <- samples$tf[,ii] *(tmax[ii]-tmin[ii]) + tmin[ii]
}
return(list(samples=samples$tf,tmin=tmin,tmax=tmax))
}
nSim <- 30; nVar = 3
year <- 2013; xn <- 3
mu <- c(0.5,0.7,0.14)
tmin.prior <- c(0.1,3,0)
tmax.prior <- c(0.9,30,0.001524)
samples <- getSamples(predictor = 'y',
prior = 'flat',
nVar = nVar, year = 2013,
xn = xn, nSim = 30)
setwd("~/Dropbox/Toshiba Projects/Compare Optimization Bayesian Calibration/Models/BCTutorial/with_predictive_inference")
rm(list = ls())
library(ggplot2)
source('utilities.R')
library(plyr)
getPred <- function(predictor, prior, nVar, year, xn, nSim) {
directory <- paste(nVar,'CalibrationParams/',sep='')
D.COMP <- read.csv(paste(directory,'AY',year,'_xn',xn,
'_DATACOMP.csv',sep=''),header=TRUE)
D.FIELD <- read.csv(paste(directory,'AY',year,'_xn',xn,
'_DATAFIELD.csv',sep=''),header=TRUE)
folder <- paste(predictor,'_',prior,'_',xn,'xn_',
nVar,'tc_',nSim,'sim_',
'AY',year,sep='')
load(paste(directory,'results/',folder,'/',
'modelOutput_',prior,'_',xn,'xn_',
nVar,'tc_',nSim,'sim_',
'AY',year,'.rda',sep=''))
samples <- rstan::extract(fit)
if (predictor == 'y'){
pred <- samples$y_pred
}else{
pred <- samples$eta_pred
}
eta <- D.COMP[,1]
eta_mu <- mean(eta, na.rm = TRUE) # mean value
eta_sd <- sd(eta, na.rm = TRUE) # standard deviation
return(pred*eta_sd+eta_mu)
}
transformPred <- function(y.pred, x){
n <- nrow(y.pred); m <- ncol(y.pred)
result <- matrix(data = NA, nrow = n*m, ncol = 2)
for(ii in (1:m)){
result[(((ii-1)*n+1):(ii*n)),1] <- y.pred[,ii]
result[(((ii-1)*n+1):(ii*n)),2] <- x[ii]
}
result <- as.data.frame(result)
colnames(result) <- c('y','x')
return(result)
}
nVar <- 3; nSim <- 30
year <- 2013; xn <- 3
mainDir <- paste(nVar,'CalibrationParams/',sep='')
subDir <- 'results'
D.COMP <- read.csv(paste(mainDir,'AY',year,'_xn',xn,
'_DATACOMP.csv',sep=''),header=TRUE)
D.FIELD <- read.csv(paste(mainDir,'AY',year,'_xn',xn,
'_DATAFIELD.csv',sep=''),header=TRUE)
y.meas <- D.FIELD[,1]; eta <- D.COMP[,1]
eta_mu <- mean(eta, na.rm = TRUE) # mean value
eta_sd <- sd(eta, na.rm = TRUE) # standard deviation
y.pred.flat <- getPred('y', 'flat', nVar, year, xn, nSim)
eta.pred.flat <- getPred('eta', 'flat', nVar, year, xn, nSim)
bias.flat <- y.pred.flat-eta.pred.flat
bias.std.flat <- bias.flat / rep.row((y.meas),nrow(bias.flat))
y.mu.pred.flat <- colMeans(y.pred.flat)
cvrmse <- function(sim,obs){
n <- length(sim)
cvrmse <- 100*(sqrt(sum((sim-obs)^2,na.rm=TRUE)/(n-1))/mean(obs,na.rm=TRUE))
return(cvrmse)
}
nmbe <- function(sim,obs){
n <- length(sim)
nmbe <- 100*(sum(sim-obs,na.rm=TRUE)/((n-1)*mean(obs,na.rm=TRUE)))
return(nmbe)
}
print(cvrmse(y.mu.pred.flat,y.meas))
print('cvrmse:',cvrmse(y.mu.pred.flat,y.meas))
cat('cvrmse:',cvrmse(y.mu.pred.flat,y.meas))
cat('nmbe:',nmbe(y.mu.pred.flat,y.meas))
y.pred.normNarrow <- getPred('y', 'normal_stdev0_05', nVar, year, xn, nSim)
eta.pred.normNarrow <- getPred('eta', 'normal_stdev0_05', nVar, year, xn, nSim)
bias.normNarrow <- y.pred.normNarrow-eta.pred.normNarrow
bias.std.normNarrow <- bias.normNarrow / rep.row((y.meas),nrow(bias.normNarrow))
y.mu.pred.normNarrow <- colMeans(y.pred.normNarrow)
cat('cvrmse:',cvrmse(y.mu.pred.normNarrow,y.meas))
cat('nmbe:',nmbe(y.mu.pred.normNarrow,y.meas))
y.mu.pred.normWide <- colMeans(y.pred.normWide)
y.pred.normWide <- getPred('y', 'normal_stdev0_2', nVar, year, xn, nSim)
eta.pred.normWide <- getPred('eta', 'normal_stdev0_2', nVar, year, xn, nSim)
bias.normWide <- y.pred.normWide-eta.pred.normWide
bias.std.normWide <- bias.normWide / rep.row((y.meas),nrow(bias.normWide))
y.mu.pred.normWide <- colMeans(y.pred.normWide)
cat('cvrmse:',cvrmse(y.mu.pred.normWide,y.meas))
cat('nmbe:',nmbe(y.mu.pred.normWide,y.meas))
x1=c(2,4,8)
x2=c(1,2,3)
x1*t(x2)
t(x2)
x1%*%t(x2)
x1=c(1,2,3)
x1=vector()
x1=c(1,2,3)
x1
x1=vector(c(1,2,3))
x1=as.vector(x1)
x1
t(x1)
x1*t(x1)
x1%*%t(x1)
t(x1)%*%(x1)
t(x1)
x1
x2=t(x1)
x1=t(x2)
x2%*%x1
beta=as.vector(c(2,4,6))
beta=as.matrix(beta)
beta=t(beta)
x1=t(x1)
x2=t(x2)
beta*x1%*%x2
x1
x2
x1%*%x2
beta*x1%*%x2
beta
beta*x1
(beta*x1)%*%x2
x=c(1,0,0;2,1,0)
setwd("~/Documents/GitHub/bc-stan/src")
library(rstan)
# read in field and computer simulation data
DATACOMP <- read.csv("DATACOMP.csv", header = TRUE)
DATAFIELD <- read.csv ("DATAFIELD.csv", header = TRUE)
# get dimensions of dataset
p <- ncol(DATAFIELD) - 1 # number of input factors
q <- ncol(DATACOMP) - p - 1 # number of calibration parameters
n <- nrow(DATAFIELD) # sample size of observed field data
m <- nrow(DATACOMP) # sample size of computer simulation data
# extract data from DATAFIELD (Table 3) and DATACOMP (Table 4)
y <- DATAFIELD[,1] # observed output
xf <- DATAFIELD[,2:(1+p)] # observed input
eta <- DATACOMP[,1] # simulation output
xc <- DATACOMP[,2:(1+p)] # simulation input
tc <- DATACOMP[,(2+p):(1+p+q)] # calibration parameters
x_pred <- xf # design points for predictions
n_pred <- nrow(x_pred) # design points for predictions
# standardization of output y and eta
eta_mu <- mean(eta, na.rm = TRUE) # mean value
eta_sd <- sd(eta, na.rm = TRUE) # standard deviation
y <- (y - eta_mu) / eta_sd
eta <- (eta - eta_mu) / eta_sd
# Put design points xf and xc on [0,1]
x <- rbind(as.matrix(xf), as.matrix(xc))
for (i in (1:ncol(x))){
x_min <- min(x[,i], na.rm = TRUE)
x_max <- max(x[,i], na.rm = TRUE)
xf[,i] <- (xf[,i] - x_min) / (x_max - x_min)
xc[,i] <- (xc[,i] - x_min) / (x_max - x_min)
x_pred[,i] <- (x_pred[,i] - x_min) / (x_max - x_min)
}
# Put calibration parameters t on domain [0,1]
for (j in (1:ncol(tc))){
tc_min <- min(tc[,j], na.rm = TRUE)
tc_max <- max(tc[,j], na.rm = TRUE)
tc[,j] <- (tc[,j] - tc_min) / (tc_max - tc_min)
}
# create data as list for input to Stan
stan_data <- list(n=n, m=m, n_pred=n_pred, p=p, y=y, q=q, eta=eta,
xf=as.matrix(xf), xc=as.matrix(xc),
x_pred=as.matrix(x_pred), tc=as.matrix(tc))
# set stan to execute multiple Markov chains in parallel
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
fit <- stan(file = "bcWithPred.stan",
data = stan_data,
iter = 500,
chains = 2)
library(rstan)
# read in field and computer simulation data
DATACOMP <- read.csv("DATACOMP.csv", header = TRUE)
DATAFIELD <- read.csv ("DATAFIELD.csv", header = TRUE)
# get dimensions of dataset
p <- ncol(DATAFIELD) - 1 # number of input factors
q <- ncol(DATACOMP) - p - 1 # number of calibration parameters
n <- nrow(DATAFIELD) # sample size of observed field data
m <- nrow(DATACOMP) # sample size of computer simulation data
# extract data from DATAFIELD (Table 3) and DATACOMP (Table 4)
y <- DATAFIELD[,1] # observed output
xf <- DATAFIELD[,2:(1+p)] # observed input
eta <- DATACOMP[,1] # simulation output
xc <- DATACOMP[,2:(1+p)] # simulation input
tc <- DATACOMP[,(2+p):(1+p+q)] # calibration parameters
x_pred <- xf # design points for predictions
n_pred <- nrow(x_pred) # design points for predictions
# standardization of output y and eta
eta_mu <- mean(eta, na.rm = TRUE) # mean value
eta_sd <- sd(eta, na.rm = TRUE) # standard deviation
y <- (y - eta_mu) / eta_sd
eta <- (eta - eta_mu) / eta_sd
# Put design points xf and xc on [0,1]
x <- rbind(as.matrix(xf), as.matrix(xc))
for (i in (1:ncol(x))){
x_min <- min(x[,i], na.rm = TRUE)
x_max <- max(x[,i], na.rm = TRUE)
xf[,i] <- (xf[,i] - x_min) / (x_max - x_min)
xc[,i] <- (xc[,i] - x_min) / (x_max - x_min)
x_pred[,i] <- (x_pred[,i] - x_min) / (x_max - x_min)
}
# Put calibration parameters t on domain [0,1]
for (j in (1:ncol(tc))){
tc_min <- min(tc[,j], na.rm = TRUE)
tc_max <- max(tc[,j], na.rm = TRUE)
tc[,j] <- (tc[,j] - tc_min) / (tc_max - tc_min)
}
# create data as list for input to Stan
stan_data <- list(n=n, m=m, n_pred=n_pred, p=p, y=y, q=q, eta=eta,
xf=as.matrix(xf), xc=as.matrix(xc),
x_pred=as.matrix(x_pred), tc=as.matrix(tc))
# set stan to execute multiple Markov chains in parallel
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
# run model in stan
fit <- stan(file = "bcWithPred.stan",
data = stan_data,
iter = 500,
chains = 2)
stan_trace(fit, pars = c("tf", "beta_eta", "beta_delta",
"lambda_eta", "lambda_delta", "lambda_e"))
print(fit, pars = c("tf", "beta_eta", "beta_delta",
"lambda_eta", "lambda_delta", "lambda_e"))
stan_hist(fit, pars = c("tf"))
samples <- rstan::extract(fit)
y_pred <- samples$y_pred * eta_sd + eta_mu
n_samples <- nrow(y_pred)
for (i in (1:p)) {
field_data <- data.frame(yf=DATAFIELD[, 1],
xf=signif(DATAFIELD[, (i+1)], 3))
pred_data <- matrix(data=t(y_pred),
nrow=length(y_pred), ncol = 1)
plot_data <- data.frame(apply(field_data, 2, rep,
n_samples), pred = pred_data)
# save plot as png file
png(paste("plot", i, ".png", sep = ""))
plt <- ggplot(data = plot_data, aes(y=pred, x=xf, group=xf)) +
geom_boxplot(outlier.size=0.2) +
geom_point(data = field_data, aes(x=xf, y=yf),
color="#D55E00", size=0.8)
print(plt)
dev.off()
}
stan_trace(fit, pars = c("tf", "beta_eta", "beta_delta",
"lambda_eta", "lambda_delta", "lambda_e"))
setwd("~/Documents/GitHub/bc-stan/src")
library(rstan)
# read in field and computer simulation data
DATACOMP <- read.csv("DATACOMP.csv", header = TRUE)
DATAFIELD <- read.csv ("DATAFIELD.csv", header = TRUE)
# get dimensions of dataset
p <- ncol(DATAFIELD) - 1 # number of input factors
q <- ncol(DATACOMP) - p - 1 # number of calibration parameters
n <- nrow(DATAFIELD) # sample size of observed field data
m <- nrow(DATACOMP) # sample size of computer simulation data
# extract data from DATAFIELD (Table 3) and DATACOMP (Table 4)
y <- DATAFIELD[,1] # observed output
xf <- DATAFIELD[,2:(1+p)] # observed input
eta <- DATACOMP[,1] # simulation output
xc <- DATACOMP[,2:(1+p)] # simulation input
tc <- DATACOMP[,(2+p):(1+p+q)] # calibration parameters
x_pred <- xf # design points for predictions
n_pred <- nrow(x_pred) # design points for predictions
# standardization of output y and eta
eta_mu <- mean(eta, na.rm = TRUE) # mean value
eta_sd <- sd(eta, na.rm = TRUE) # standard deviation
y <- (y - eta_mu) / eta_sd
eta <- (eta - eta_mu) / eta_sd
# Put design points xf and xc on [0,1]
x <- rbind(as.matrix(xf), as.matrix(xc))
for (i in (1:ncol(x))){
x_min <- min(x[,i], na.rm = TRUE)
x_max <- max(x[,i], na.rm = TRUE)
xf[,i] <- (xf[,i] - x_min) / (x_max - x_min)
xc[,i] <- (xc[,i] - x_min) / (x_max - x_min)
x_pred[,i] <- (x_pred[,i] - x_min) / (x_max - x_min)
}
# Put calibration parameters t on domain [0,1]
for (j in (1:ncol(tc))){
tc_min <- min(tc[,j], na.rm = TRUE)
tc_max <- max(tc[,j], na.rm = TRUE)
tc[,j] <- (tc[,j] - tc_min) / (tc_max - tc_min)
}
# create data as list for input to Stan
stan_data <- list(n=n, m=m, n_pred=n_pred, p=p, y=y, q=q, eta=eta,
xf=as.matrix(xf), xc=as.matrix(xc),
x_pred=as.matrix(x_pred), tc=as.matrix(tc))
# set stan to execute multiple Markov chains in parallel
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
# run model in stan
fit <- stan(file = "bcWithPred.stan",
data = stan_data,
iter = 500,
chains = 2)
